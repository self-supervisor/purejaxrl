{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax devices [StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]\n",
      "jax devices [StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/augustine/anaconda3/envs/cleanrl_jax/lib/python3.8/site-packages/flax/struct.py:136: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
      "/home/augustine/anaconda3/envs/cleanrl_jax/lib/python3.8/site-packages/flax/struct.py:136: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
      "/home/augustine/anaconda3/envs/cleanrl_jax/lib/python3.8/site-packages/flax/struct.py:136: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
      "/home/augustine/anaconda3/envs/cleanrl_jax/lib/python3.8/site-packages/flax/struct.py:136: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.16 s\n",
      "return|ent_coef|lr|transition_lr|max_grad_norm|schedule_accelerator|num_envs|num_minibatches|clip_eps\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "259.90|0.0009999999|0.0025|1e-04|0.5|1.0|2.0|0.02\n",
      "259.90|0.0009999999|0.0025|1e-04|0.5|1.0|2.0|0.19999999\n",
      "259.90|0.0009999999|0.0025|1e-04|0.5|1.0|2.0|2.0\n",
      "246.20|0.0|0.0025|1e-04|0.049999997|1.0|2.0|0.02\n",
      "246.20|0.0|0.0025|1e-04|0.049999997|1.0|2.0|0.19999999\n",
      "246.20|0.0|0.0025|1e-04|0.049999997|1.0|2.0|2.0\n",
      "244.40|0.0009999999|0.0002|1e-04|5.0|1.0|2.0|0.02\n",
      "244.40|0.0009999999|0.0002|1e-04|5.0|1.0|2.0|0.19999999\n",
      "244.40|0.0009999999|0.0002|1e-04|5.0|1.0|2.0|2.0\n",
      "237.40|0.01|0.0025|1e-04|0.5|1.0|2.0|0.02\n",
      "237.40|0.01|0.0025|1e-04|0.5|1.0|2.0|0.19999999\n",
      "237.40|0.01|0.0025|1e-04|0.5|1.0|2.0|2.0\n",
      "236.80|0.01|0.0002|1e-04|5.0|1.0|2.0|0.02\n",
      "236.80|0.01|0.0002|1e-04|5.0|1.0|2.0|0.19999999\n",
      "236.80|0.01|0.0002|1e-04|5.0|1.0|2.0|2.0\n",
      "224.40|0.0009999999|0.0025|1e-04|0.049999997|1.0|2.0|0.02\n",
      "224.40|0.0009999999|0.0025|1e-04|0.049999997|1.0|2.0|0.19999999\n",
      "224.40|0.0009999999|0.0025|1e-04|0.049999997|1.0|2.0|2.0\n",
      "220.70|0.01|0.0025|1e-04|0.049999997|1.0|2.0|0.02\n",
      "220.70|0.01|0.0025|1e-04|0.049999997|1.0|2.0|0.19999999\n",
      "220.70|0.01|0.0025|1e-04|0.049999997|1.0|2.0|2.0\n",
      "214.90|0.0|0.0002|1e-04|5.0|1.0|2.0|0.02\n",
      "214.90|0.0|0.0002|1e-04|5.0|1.0|2.0|0.19999999\n",
      "214.90|0.0|0.0002|1e-04|5.0|1.0|2.0|2.0\n",
      "211.40|0.01|0.0002|1e-04|0.5|1.0|2.0|0.02\n",
      "211.40|0.01|0.0002|1e-04|0.5|1.0|2.0|0.19999999\n",
      "211.40|0.01|0.0002|1e-04|0.5|1.0|2.0|2.0\n",
      "204.70|0.0|0.0002|1e-04|0.5|1.0|2.0|0.02\n",
      "204.70|0.0|0.0002|1e-04|0.5|1.0|2.0|0.19999999\n",
      "204.70|0.0|0.0002|1e-04|0.5|1.0|2.0|2.0\n",
      "203.90|0.0|0.0025|1e-04|0.5|1.0|2.0|0.02\n",
      "203.90|0.0|0.0025|1e-04|0.5|1.0|2.0|0.19999999\n",
      "203.90|0.0|0.0025|1e-04|0.5|1.0|2.0|2.0\n",
      "199.30|0.0009999999|0.0002|1e-04|0.5|1.0|2.0|0.02\n",
      "199.30|0.0009999999|0.0002|1e-04|0.5|1.0|2.0|0.19999999\n",
      "199.30|0.0009999999|0.0002|1e-04|0.5|1.0|2.0|2.0\n",
      "194.30|0.01|0.0025|1e-04|5.0|1.0|2.0|0.02\n",
      "194.30|0.01|0.0025|1e-04|5.0|1.0|2.0|0.19999999\n",
      "194.30|0.01|0.0025|1e-04|5.0|1.0|2.0|2.0\n",
      "188.90|0.0|0.0025|1e-04|5.0|1.0|2.0|0.02\n",
      "188.90|0.0|0.0025|1e-04|5.0|1.0|2.0|0.19999999\n",
      "188.90|0.0|0.0025|1e-04|5.0|1.0|2.0|2.0\n",
      "180.30|0.0009999999|0.0025|1e-04|5.0|1.0|2.0|0.02\n",
      "180.30|0.0009999999|0.0025|1e-04|5.0|1.0|2.0|0.19999999\n",
      "180.30|0.0009999999|0.0025|1e-04|5.0|1.0|2.0|2.0\n",
      "148.80|0.0|0.0002|1e-04|0.049999997|1.0|2.0|0.02\n",
      "148.80|0.0|0.0002|1e-04|0.049999997|1.0|2.0|0.19999999\n",
      "148.80|0.0|0.0002|1e-04|0.049999997|1.0|2.0|2.0\n",
      "145.10|0.0009999999|0.0002|1e-04|0.049999997|1.0|2.0|0.02\n",
      "145.10|0.0009999999|0.0002|1e-04|0.049999997|1.0|2.0|0.19999999\n",
      "145.10|0.0009999999|0.0002|1e-04|0.049999997|1.0|2.0|2.0\n",
      "144.10|0.01|0.0002|1e-04|0.049999997|1.0|2.0|0.02\n",
      "144.10|0.01|0.0002|1e-04|0.049999997|1.0|2.0|0.19999999\n",
      "144.10|0.01|0.0002|1e-04|0.049999997|1.0|2.0|2.0\n",
      "30.80|0.01|0.0|1e-04|5.0|1.0|2.0|0.02\n",
      "30.80|0.01|0.0|1e-04|5.0|1.0|2.0|0.19999999\n",
      "30.80|0.01|0.0|1e-04|5.0|1.0|2.0|2.0\n",
      "30.70|0.0|0.0|1e-04|5.0|1.0|2.0|0.02\n",
      "30.70|0.0|0.0|1e-04|5.0|1.0|2.0|0.19999999\n",
      "30.70|0.0|0.0|1e-04|5.0|1.0|2.0|2.0\n",
      "30.60|0.0009999999|0.0|1e-04|5.0|1.0|2.0|0.02\n",
      "30.60|0.0009999999|0.0|1e-04|5.0|1.0|2.0|0.19999999\n",
      "30.60|0.0009999999|0.0|1e-04|5.0|1.0|2.0|2.0\n",
      "28.30|0.0|0.0|1e-04|0.5|1.0|2.0|0.02\n",
      "28.30|0.0|0.0|1e-04|0.5|1.0|2.0|0.19999999\n",
      "28.30|0.0|0.0|1e-04|0.5|1.0|2.0|2.0\n",
      "28.30|0.0009999999|0.0|1e-04|0.5|1.0|2.0|0.02\n",
      "28.30|0.0009999999|0.0|1e-04|0.5|1.0|2.0|0.19999999\n",
      "28.30|0.0009999999|0.0|1e-04|0.5|1.0|2.0|2.0\n",
      "28.30|0.01|0.0|1e-04|0.5|1.0|2.0|0.02\n",
      "28.30|0.01|0.0|1e-04|0.5|1.0|2.0|0.19999999\n",
      "28.30|0.01|0.0|1e-04|0.5|1.0|2.0|2.0\n",
      "26.10|0.0|0.0|1e-04|0.049999997|1.0|2.0|0.02\n",
      "26.10|0.0|0.0|1e-04|0.049999997|1.0|2.0|0.19999999\n",
      "26.10|0.0|0.0|1e-04|0.049999997|1.0|2.0|2.0\n",
      "26.10|0.0009999999|0.0|1e-04|0.049999997|1.0|2.0|0.02\n",
      "26.10|0.0009999999|0.0|1e-04|0.049999997|1.0|2.0|0.19999999\n",
      "26.10|0.0009999999|0.0|1e-04|0.049999997|1.0|2.0|2.0\n",
      "26.10|0.01|0.0|1e-04|0.049999997|1.0|2.0|0.02\n",
      "26.10|0.01|0.0|1e-04|0.049999997|1.0|2.0|0.19999999\n",
      "26.10|0.01|0.0|1e-04|0.049999997|1.0|2.0|2.0\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "print(\"jax devices\", jax.devices())\n",
    "import jax.numpy as jnp\n",
    "import time\n",
    "from train import make_train\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import wandb\n",
    "from config import config\n",
    "\n",
    "\n",
    "def generate_combinations(\n",
    "    lr,\n",
    "    ent_coef,\n",
    "    transition_model_lr,\n",
    "    max_grad_norm,\n",
    "    schedule_accelerator,\n",
    "    num_envs,\n",
    "    num_minibatches,\n",
    "    clip_eps,\n",
    "):\n",
    "    \"\"\"\n",
    "    from chatGPT\n",
    "    \"\"\"\n",
    "    # Generate all possible combinations of lr, ent_coef, and vf_coef\n",
    "    combinations = np.array(\n",
    "        list(\n",
    "            product(\n",
    "                lr,\n",
    "                ent_coef,\n",
    "                transition_model_lr,\n",
    "                max_grad_norm,\n",
    "                schedule_accelerator,\n",
    "                num_envs,\n",
    "                num_minibatches,\n",
    "                clip_eps,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Split the combinations into separate arrays\n",
    "    lr_combinations = combinations[:, 0]\n",
    "    ent_coef_combinations = combinations[:, 1]\n",
    "    transition_model_lr_combinations = combinations[:, 2]\n",
    "    max_grad_norm_combinations = combinations[:, 3]\n",
    "    schedule_accelerator_combinations = combinations[:, 4]\n",
    "    num_envs_combinations = combinations[:, 5]\n",
    "    num_minibatches_combinations = combinations[:, 6]\n",
    "    clips_eps_combinations = combinations[:, 7]\n",
    "\n",
    "    # Return a tuple of the resulting arrays\n",
    "    return (\n",
    "        lr_combinations,\n",
    "        ent_coef_combinations,\n",
    "        transition_model_lr_combinations,\n",
    "        max_grad_norm_combinations,\n",
    "        schedule_accelerator_combinations,\n",
    "        num_envs_combinations,\n",
    "        num_minibatches_combinations,\n",
    "        clips_eps_combinations,\n",
    "    )\n",
    "\n",
    "\n",
    "# group = wandb.util.generate_id()\n",
    "\n",
    "config.update({\"ANNEAL_LR\": True})\n",
    "config.update({\"NUM_ENVS\": 2})\n",
    "config.update({\"NUM_MINIBATCHES\": 1})\n",
    "ent_coef_search = [0.0, 0.001, 0.01]\n",
    "lr_search = [0.00025, 0.0025, 0.000025]\n",
    "transition_model_lr_search = [0.0001]\n",
    "max_grad_norm_search = [0.05, 0.5, 5]\n",
    "schedule_accelerator_search = [1.0]\n",
    "num_envs = [config[\"NUM_ENVS\"]]\n",
    "num_minibatches = [config[\"NUM_MINIBATCHES\"]]\n",
    "clip_eps = [0.02, 0.2, 2]\n",
    "(\n",
    "    lr_combinations,\n",
    "    ent_coef_combinations,\n",
    "    transition_model_lr_combinations,\n",
    "    max_grad_norm_combinations,\n",
    "    schedule_accelerator_combinations,\n",
    "    num_envs_combinations,\n",
    "    num_minibatches_combinations,\n",
    "    clips_eps_combinations,\n",
    ") = generate_combinations(\n",
    "    lr_search,\n",
    "    ent_coef_search,\n",
    "    transition_model_lr_search,\n",
    "    max_grad_norm_search,\n",
    "    schedule_accelerator_search,\n",
    "    num_envs,\n",
    "    num_minibatches,\n",
    "    clip_eps,\n",
    ")\n",
    "lr_combinations = jnp.array(lr_combinations)\n",
    "ent_coef_combinations = jnp.array(ent_coef_combinations)\n",
    "transition_model_lr_combinations = jnp.array(transition_model_lr_combinations)\n",
    "max_grad_norm_combinations = jnp.array(max_grad_norm_combinations)\n",
    "schedule_accelerator_combinations = jnp.array(schedule_accelerator_combinations)\n",
    "num_envs_combinations = jnp.array(num_envs_combinations)\n",
    "num_minibatches_combinations = jnp.array(num_minibatches_combinations)\n",
    "clips_eps_combinations = jnp.array(clips_eps_combinations)\n",
    "combinations = [\n",
    "    lr_combinations,\n",
    "    ent_coef_combinations,\n",
    "    transition_model_lr_combinations,\n",
    "    max_grad_norm_combinations,\n",
    "    schedule_accelerator_combinations,\n",
    "    num_envs_combinations.astype(int),\n",
    "    num_minibatches_combinations.astype(int),\n",
    "    clips_eps_combinations,\n",
    "]\n",
    "\n",
    "NUMBER_OF_SEEDS = 5\n",
    "# num_minibatches_combinations = jnp.ones([81,], dtype=jnp.int32) * 2\n",
    "\n",
    "rng = jax.random.PRNGKey(NUMBER_OF_SEEDS * len(combinations))\n",
    "rngs = jax.random.split(rng, NUMBER_OF_SEEDS)\n",
    "\n",
    "train_vvjit = jax.jit(\n",
    "    jax.vmap(jax.vmap(make_train(config), in_axes=(None, 0)), in_axes=(0, None))\n",
    ")\n",
    "t0 = time.time()\n",
    "outs = jax.block_until_ready(train_vvjit(combinations, rngs))\n",
    "print(f\"time: {time.time() - t0:.2f} s\")\n",
    "\n",
    "dict_outs = {}\n",
    "combinations = jnp.stack(combinations, axis=1)\n",
    "for i in range(len(combinations)):\n",
    "    (\n",
    "        lr,\n",
    "        ent_coef,\n",
    "        transition_lr,\n",
    "        max_grad_norm,\n",
    "        schedule_accelerator,\n",
    "        num_envs,\n",
    "        num_minibatches,\n",
    "        clip_eps,\n",
    "    ) = combinations[i]\n",
    "    to_plot_ent_coef = str(round(ent_coef, 4))\n",
    "    to_plot_lr = str(round(lr, 4))\n",
    "    to_plot_transition_model_lr = str(round(transition_lr, 4))\n",
    "    to_plot_max_grad_norm = str(round(max_grad_norm, 4))\n",
    "    to_plot_schedule_accelerator = str(round(schedule_accelerator, 4))\n",
    "    to_plot_num_envs = str(round(num_envs, 4))\n",
    "    to_plot_num_minibatches = str(round(num_minibatches, 4))\n",
    "    to_plot_clip_eps = str(round(clip_eps, 4))\n",
    "    new_config = {\n",
    "        \"LR\": to_plot_lr,\n",
    "        \"TRANSITION_MODEL_LR\": to_plot_transition_model_lr,\n",
    "        \"ENT_COEF\": to_plot_ent_coef,\n",
    "        \"MAX_GRAD_NORM\": to_plot_max_grad_norm,\n",
    "        \"SCHEDULE_ACCELERATOR\": to_plot_schedule_accelerator,\n",
    "        \"NUM_ENVS\": to_plot_num_envs,\n",
    "        \"NUM_MINIBATCHES\": to_plot_num_minibatches,\n",
    "        \"CLIP_EPS\": to_plot_clip_eps,\n",
    "    }\n",
    "    config.update(new_config)\n",
    "\n",
    "    # wandb.init(project=\"purejaxrl\", entity=\"self-supervisor\", config=config, group=group)\n",
    "    # list_to_log = [j.item() for j in outs[\"metrics\"][\"returned_episode_returns\"][i].mean(0).mean(-1).reshape(-1)]\n",
    "    # for a_val_to_log in list_to_log:\n",
    "    #     wandb.log({\"episode_returns\": a_val_to_log})\n",
    "    # wandb.finish()\n",
    "\n",
    "    # plt.plot(\n",
    "    #     outs[\"metrics\"][\"returned_episode_returns\"][i].mean(0).mean(-1).reshape(-1),\n",
    "    # )\n",
    "    dict_outs[\n",
    "        f\"ent_coef={to_plot_ent_coef}, lr={to_plot_lr}, transition_lr={to_plot_transition_model_lr}, max_grad_norm={to_plot_max_grad_norm}, schedule_accelerator={to_plot_schedule_accelerator}, num_envs={to_plot_num_envs}, num_minibatches={to_plot_num_minibatches}, clip_eps={to_plot_clip_eps}\"\n",
    "    ] = round(\n",
    "        outs[\"metrics\"][\"returned_episode_returns\"][i]\n",
    "        .mean(0)\n",
    "        .mean(-1)\n",
    "        .reshape(-1)[:-1000]\n",
    "        .mean()\n",
    "        .item(),\n",
    "        1,\n",
    "    )\n",
    "# plt.savefig(\"hyperparam_search.png\")\n",
    "# plt.close()\n",
    "dict_outs = {\n",
    "    k: v\n",
    "    for k, v in sorted(\n",
    "        dict_outs.items(), key=lambda item: np.mean(item[1]), reverse=True\n",
    "    )\n",
    "}\n",
    "headers = [\n",
    "    \"return\",\n",
    "    \"ent_coef\",\n",
    "    \"lr\",\n",
    "    \"transition_lr\",\n",
    "    \"max_grad_norm\",\n",
    "    \"schedule_accelerator\",\n",
    "    \"num_envs\",\n",
    "    \"num_minibatches\",\n",
    "    \"clip_eps\",\n",
    "]\n",
    "print(\"|\".join(headers))\n",
    "print(\"-\" * (len(headers) * 12))\n",
    "for key, value in dict_outs.items():\n",
    "    (\n",
    "        ent_coef,\n",
    "        lr,\n",
    "        transition_lr,\n",
    "        max_grad_norm,\n",
    "        schedule_accelerator,\n",
    "        num_envs,\n",
    "        num_minibatches,\n",
    "        clip_eps,\n",
    "    ) = key.split(\", \")\n",
    "    row_values = [\n",
    "        \"{:.2f}\".format(value),\n",
    "        ent_coef.split(\"=\")[1],\n",
    "        lr.split(\"=\")[1],\n",
    "        transition_lr.split(\"=\")[1],\n",
    "        max_grad_norm.split(\"=\")[1],\n",
    "        schedule_accelerator.split(\"=\")[1],\n",
    "        num_envs.split(\"=\")[1],\n",
    "        clip_eps.split(\"=\")[1],\n",
    "    ]\n",
    "    print(\"|\".join(row_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanrl_jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
